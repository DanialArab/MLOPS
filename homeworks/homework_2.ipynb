{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb2f7538",
   "metadata": {},
   "source": [
    "Q1. Install the package\n",
    "To get started with MLflow you'll need to install the appropriate Python package.\n",
    "\n",
    "For this we recommend creating a separate Python environment, for example, you can use conda environments, and then install the package there with pip or conda.\n",
    "\n",
    "Once you installed the package, run the command mlflow --version and check the output.\n",
    "\n",
    "What's the version that you have?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6506c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3189ff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLflow version is 2.3.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"The MLflow version is {mlflow.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c17bbac",
   "metadata": {},
   "source": [
    "Q2. Download and preprocess the data\n",
    "\n",
    "So what's the size of the saved DictVectorizer file?\n",
    "\n",
    "    54 kB\n",
    "    154 kB\n",
    "    54 MB\n",
    "    154 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5fb672",
   "metadata": {},
   "outputs": [],
   "source": [
    "154"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "813dac3b",
   "metadata": {},
   "source": [
    "Q3. Train a model with autolog\n",
    "\n",
    "What is the value of the max_depth parameter:\n",
    "\n",
    "    4\n",
    "    6\n",
    "    8\n",
    "    10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df5dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39e5598d",
   "metadata": {},
   "source": [
    "Q4. Tune model hyperparameters\n",
    "\n",
    "What's the best validation RMSE that you got?\n",
    "\n",
    "    1.85\n",
    "    2.15\n",
    "    2.45\n",
    "    2.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ac534",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.45"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90a8911d",
   "metadata": {},
   "source": [
    "Q5. Promote the best model to the model registry\n",
    "\n",
    "What is the test RMSE of the best model?\n",
    "\n",
    "    1.885\n",
    "    2.185\n",
    "    2.555\n",
    "    2.955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96516b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.285 , the closest was 2.185"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4309eeb",
   "metadata": {},
   "source": [
    "Q6. Model metadata\n",
    "Now explore your best model in the model registry using UI. What information does the model registry contain about each model?\n",
    "\n",
    "    Version number\n",
    "    Source experiment\n",
    "    Model signature\n",
    "    All the above answers are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cf6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "All"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
